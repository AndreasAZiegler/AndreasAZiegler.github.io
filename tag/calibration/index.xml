<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Calibration | Andreas Ziegler</title><link>https://andreasaziegler.github.io/tag/calibration/</link><atom:link href="https://andreasaziegler.github.io/tag/calibration/index.xml" rel="self" type="application/rss+xml"/><description>Calibration</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2023 Andreas Ziegler</copyright><lastBuildDate>Sun, 21 Feb 2021 00:00:00 +0000</lastBuildDate><image><url>https://andreasaziegler.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Calibration</title><link>https://andreasaziegler.github.io/tag/calibration/</link></image><item><title>Event-camera, camera and robot arm calibration</title><link>https://andreasaziegler.github.io/teaching/calibration/</link><pubDate>Sun, 21 Feb 2021 00:00:00 +0000</pubDate><guid>https://andreasaziegler.github.io/teaching/calibration/</guid><description>&lt;h2 id="description">Description&lt;/h2>
&lt;p>The cognitive systems group at the University of Tübingen uses a table tennis robot system to conduct research on various topics around robotics, control, computer vision, machine learning and reinforcement learning. So far the system uses up to five cameras for the perception pipeline. Recently, the group added event-based cameras to the sensor suite.&lt;/p>
&lt;p>Event cameras are bio-inspired sensors that differ from conventional frame cameras: Instead of capturing images at a fixed rate, they asynchronously measure per-pixel brightness changes, and output a stream of events that encode the time, location and sign of the brightness changes. Event cameras offer attractive properties compared to traditional cameras: high temporal resolution (in the order of μs), very high dynamic range (140 dB vs. 60 dB), low power consumption, and high pixel bandwidth (on the order of kHz) resulting in reduced motion blur. Hence, event cameras have a large potential for robotics and computer vision.&lt;/p>
&lt;p>With this new sensors in place, the questions arises, how the whole system should be calibrated. Eye-to-hand (calibration of the camera and the robot arm) and camera calibration is a well studied topic in the literature. However, since event-based cameras are still relatively new, there is only very little literature on event-based camera calibration, especially for eye-to-hand calibration.&lt;/p>
&lt;p>In a first step, the student should study the state-of-the-art calibration methods relevant for our table tennis robot system. Based on this, the goal of the thesis is to develop new methods which can be used in a calibration toolbox, allowing to calibrate the system in an automatic fashion.&lt;/p>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;ul>
&lt;li>Familiar with &amp;ldquo;traditional&amp;rdquo; Computer Vision&lt;/li>
&lt;li>C++ and/or Python&lt;/li>
&lt;/ul></description></item></channel></rss>