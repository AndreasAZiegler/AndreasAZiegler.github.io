<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Event Camera | Andreas Ziegler</title><link>https://andreasaziegler.github.io/tag/event-camera/</link><atom:link href="https://andreasaziegler.github.io/tag/event-camera/index.xml" rel="self" type="application/rss+xml"/><description>Event Camera</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2023 Andreas Ziegler</copyright><lastBuildDate>Sun, 21 Feb 2021 00:00:00 +0000</lastBuildDate><image><url>https://andreasaziegler.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Event Camera</title><link>https://andreasaziegler.github.io/tag/event-camera/</link></image><item><title>Event-camera, camera and robot arm calibration</title><link>https://andreasaziegler.github.io/teaching/calibration/</link><pubDate>Sun, 21 Feb 2021 00:00:00 +0000</pubDate><guid>https://andreasaziegler.github.io/teaching/calibration/</guid><description>&lt;h2 id="description">Description&lt;/h2>
&lt;p>The cognitive systems group at the University of Tübingen uses a table tennis robot system to conduct research on various topics around robotics, control, computer vision, machine learning and reinforcement learning. So far the system uses up to five cameras for the perception pipeline. Recently, the group added event-based cameras to the sensor suite.&lt;/p>
&lt;p>Event cameras are bio-inspired sensors that differ from conventional frame cameras: Instead of capturing images at a fixed rate, they asynchronously measure per-pixel brightness changes, and output a stream of events that encode the time, location and sign of the brightness changes. Event cameras offer attractive properties compared to traditional cameras: high temporal resolution (in the order of μs), very high dynamic range (140 dB vs. 60 dB), low power consumption, and high pixel bandwidth (on the order of kHz) resulting in reduced motion blur. Hence, event cameras have a large potential for robotics and computer vision.&lt;/p>
&lt;p>With this new sensors in place, the questions arises, how the whole system should be calibrated. Eye-to-hand (calibration of the camera and the robot arm) and camera calibration is a well studied topic in the literature. However, since event-based cameras are still relatively new, there is only very little literature on event-based camera calibration, especially for eye-to-hand calibration.&lt;/p>
&lt;p>In a first step, the student should study the state-of-the-art calibration methods relevant for our table tennis robot system. Based on this, the goal of the thesis is to develop new methods which can be used in a calibration toolbox, allowing to calibrate the system in an automatic fashion.&lt;/p>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;ul>
&lt;li>Familiar with &amp;ldquo;traditional&amp;rdquo; Computer Vision&lt;/li>
&lt;li>C++ and/or Python&lt;/li>
&lt;/ul></description></item><item><title>Spiking neural network for event-based ball detection</title><link>https://andreasaziegler.github.io/teaching/snn/</link><pubDate>Sun, 21 Feb 2021 00:00:00 +0000</pubDate><guid>https://andreasaziegler.github.io/teaching/snn/</guid><description>&lt;h2 id="description">Description&lt;/h2>
&lt;p>Event cameras are bio-inspired sensors that differ from conventional frame cameras: Instead of capturing images at a fixed rate, they asynchronously measure per-pixel brightness changes, and output a stream of events that encode the time, location and sign of the brightness changes. Event cameras offer attractive properties compared to traditional cameras: high temporal resolution (in the order of μs), very high dynamic range (140 dB vs. 60 dB), low power consumption, and high pixel bandwidth (on the order of kHz) resulting in reduced motion blur. Hence, event cameras have a large potential for robotics and computer vision.&lt;/p>
&lt;p>So far, most learning approaches applied to event data, convert a batch of events into a tensor and then use conventional CNNs as network. While such approaches achieve state-of-the-art performance, they do not make use of the asynchronous nature of the event data. Spiking Neural Networks (SNNs) on the other hand are bio-inspired networks that can process output from event-based directly. SNNs process information conveyed as temporal spikes rather than numeric values. This makes SNNs an ideal counterpart for event-based cameras.&lt;/p>
&lt;p>The goal of this thesis is to investigate and evaluate how a SNN can be used together with our event-based cameras to detect and track table tennis balls. The Cognitive Systems groups has a table tennis robot system, where the developed ball tracker can be used and compared to other methods.&lt;/p>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;ul>
&lt;li>Familiar with &amp;ldquo;traditional&amp;rdquo; Computer Vision&lt;/li>
&lt;li>Deep Learning&lt;/li>
&lt;li>Python&lt;/li>
&lt;/ul></description></item></channel></rss>